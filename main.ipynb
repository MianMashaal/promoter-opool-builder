{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c7cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup Complete (Fixed get_attr).\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 1. SETUP: Imports, Config, and Helpers\n",
    "# ---------------------------------------------------------\n",
    "import sys, re, random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Auto-install if missing\n",
    "try:\n",
    "    from Bio import SeqIO\n",
    "    from Bio.Seq import Seq\n",
    "    from Bio.SeqRecord import SeqRecord\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Biopython...\")\n",
    "    !{sys.executable} -m pip install biopython pandas openpyxl\n",
    "    from Bio import SeqIO\n",
    "    from Bio.Seq import Seq\n",
    "    from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "# --- Configuration ---\n",
    "CONFIG = {\n",
    "    \"FASTA\": \"c_elegans.PRJNA13758.WS297.genomic.fa\",\n",
    "    \"GFF3\":  \"c_elegans.PRJNA13758.WS297.annotations.gff3\",\n",
    "    \"CSV\":   \"gene_set.csv\",\n",
    "    \"UPSTREAM_LEN\": 2225,\n",
    "    \"WINDOW_SIZE\": 250,\n",
    "    \"OVERLAP\": 25,\n",
    "    \"MIN_LEN\": 100,\n",
    "    \"BLOCK_OPPOSITE\": True, # If True, don't overlap CDS on opposite strand\n",
    "    \"SKIP_MT\": True,\n",
    "    \"CLIP_MARGIN\": 2,\n",
    "    \"FWD_TAIL\": \"GTCGAGCCGGAACTggtctcttgcc\",\n",
    "    \"REV_TAIL\": \"aaaatgagaccCACGCCGGCTAAAC\",\n",
    "    \"SEED\": 12345\n",
    "}\n",
    "if CONFIG[\"SEED\"]: random.seed(CONFIG[\"SEED\"])\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def clean_id(x): return re.sub(r'[^a-z0-9]+', '', str(x).strip().lower()) if x else \"\"\n",
    "\n",
    "def get_attr(attrs, key): \n",
    "    \"\"\"Parses GFF3 attribute string for a specific key (Crash-proof version).\"\"\"\n",
    "    if not attrs or key not in attrs: return None\n",
    "    # Regex searches for 'key=value', ensuring it follows a semicolon or start of line\n",
    "    # This prevents finding \"ID\" inside \"Protein_ID\"\n",
    "    match = re.search(f\"(?:^|;){key}=([^;]+)\", attrs)\n",
    "    if match:\n",
    "        return match.group(1).replace(\"Gene:\", \"\")\n",
    "    return None\n",
    "\n",
    "def break_bsai(seq_str):\n",
    "    \"\"\"Patches BsaI sites (GGTCTC/GAGACC) by mutating 1 random base.\"\"\"\n",
    "    s = list(seq_str)\n",
    "    motifs = [\"ggtctc\", \"gagacc\"]\n",
    "    patched = 0\n",
    "    while True:\n",
    "        low = \"\".join(s).lower()\n",
    "        # Find earliest motif\n",
    "        hit = min((low.find(m) for m in motifs if m in low), default=-1)\n",
    "        if hit == -1: break\n",
    "        \n",
    "        # Mutate 1 base in the 6-mer\n",
    "        k = hit + random.randint(0, 5)\n",
    "        new = random.choice([b for b in \"ACGT\" if b != s[k].upper()])\n",
    "        s[k] = new if s[k].isupper() else new.lower()\n",
    "        patched += 1\n",
    "    return \"\".join(s), patched\n",
    "\n",
    "print(\"‚úÖ Setup Complete (Fixed get_attr).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb389b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading Genome and Parsing GFF3...\n",
      "   Scanning gene aliases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pass 1: 53237586 lines [00:16, 3201680.35 lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Indexing CDS locations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pass 2: 53237586 lines [00:37, 1436942.10 lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Finalizing indices (Linking Transcripts to Genes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:00<00:00, 101.82 chroms/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parsed 32010 transcripts and built collision indices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 2. PARSING: Efficient GFF3 Processing (Maximum Speed)\n",
    "# ---------------------------------------------------------\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"‚è≥ Loading Genome and Parsing GFF3...\")\n",
    "\n",
    "# A. Load Genome\n",
    "genome = SeqIO.to_dict(SeqIO.parse(CONFIG[\"FASTA\"], \"fasta\"))\n",
    "\n",
    "# B. Load Gene List\n",
    "target_genes = pd.read_csv(CONFIG[\"CSV\"])[\"Gene\"].dropna().astype(str).unique()\n",
    "\n",
    "# --- Pass 1: Map Gene Names (Aliases -> Canonical ID) ---\n",
    "name_to_id = {}\n",
    "print(\"   Scanning gene aliases...\")\n",
    "with open(CONFIG[\"GFF3\"]) as fh:\n",
    "    for line in tqdm(fh, desc=\"Pass 1\", unit=\" lines\"):\n",
    "        if line.startswith(\"#\") or \"\\tgene\\t\" not in line: continue\n",
    "        \n",
    "        parts = line.split(\"\\t\")\n",
    "        attrs = parts[8]\n",
    "        \n",
    "        gid = None\n",
    "        if \"ID=\" in attrs:\n",
    "            gid = attrs.split(\"ID=\")[1].split(\";\")[0].replace(\"Gene:\", \"\")\n",
    "        if not gid: continue\n",
    "\n",
    "        names = {gid}\n",
    "        if \"Name=\" in attrs: names.add(attrs.split(\"Name=\")[1].split(\";\")[0])\n",
    "        if \"locus=\" in attrs: names.add(attrs.split(\"locus=\")[1].split(\";\")[0])\n",
    "        if \"sequence_name=\" in attrs: names.add(attrs.split(\"sequence_name=\")[1].split(\";\")[0])\n",
    "        if \"Alias=\" in attrs: \n",
    "            aliases = attrs.split(\"Alias=\")[1].split(\";\")[0]\n",
    "            names.update(aliases.split(\",\"))\n",
    "        \n",
    "        for n in names:\n",
    "            if n: name_to_id[clean_id(n)] = gid\n",
    "\n",
    "# --- Pass 2: Map Transcripts & CDS ---\n",
    "tx_map = defaultdict(set)       # gene_id -> {tx_ids}\n",
    "tx_props = {}                   # tx_id -> {chrom, strand, min, max}\n",
    "cds_index = defaultdict(list)   # (chrom, strand) -> [(start, end, tx_id)]\n",
    "\n",
    "print(\"   Indexing CDS locations...\")\n",
    "with open(CONFIG[\"GFF3\"]) as fh:\n",
    "    for line in tqdm(fh, desc=\"Pass 2\", unit=\" lines\"):\n",
    "        if line.startswith(\"#\"): continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 9: continue\n",
    "        \n",
    "        chrom, _, ftype, start, end, _, strand, _, attrs = parts\n",
    "        \n",
    "        if ftype != \"CDS\" and \"RNA\" not in ftype and \"transcript\" not in ftype:\n",
    "            continue\n",
    "\n",
    "        s, e = int(start), int(end)\n",
    "        \n",
    "        if ftype == \"CDS\":\n",
    "            if CONFIG[\"SKIP_MT\"] and chrom.startswith(\"MtDNA\"): continue\n",
    "            if \"Parent=\" not in attrs: continue\n",
    "            parents = attrs.split(\"Parent=\")[1].split(\";\")[0]\n",
    "            \n",
    "            for tx in parents.split(\",\"):\n",
    "                # Update Transcript Props\n",
    "                if tx not in tx_props:\n",
    "                    tx_props[tx] = {\"chrom\": chrom, \"strand\": strand, \"min\": s, \"max\": e, \"gid\": None}\n",
    "                else:\n",
    "                    if s < tx_props[tx][\"min\"]: tx_props[tx][\"min\"] = s\n",
    "                    if e > tx_props[tx][\"max\"]: tx_props[tx][\"max\"] = e\n",
    "                \n",
    "                # Store tx_id instead of gid for now (faster)\n",
    "                cds_index[(chrom, strand)].append((s, e, tx))\n",
    "                if CONFIG[\"BLOCK_OPPOSITE\"]:\n",
    "                    cds_index[chrom].append((s, e, tx))\n",
    "\n",
    "        else:\n",
    "            if \"ID=\" in attrs and \"Parent=\" in attrs:\n",
    "                tx_id = attrs.split(\"ID=\")[1].split(\";\")[0]\n",
    "                parent = attrs.split(\"Parent=\")[1].split(\";\")[0].replace(\"Gene:\", \"\")\n",
    "                gid = name_to_id.get(clean_id(parent))\n",
    "                if gid:\n",
    "                    tx_map[gid].add(tx_id)\n",
    "                    if tx_id in tx_props: tx_props[tx_id][\"gid\"] = gid\n",
    "\n",
    "# --- Finalize Indices (Optimized) ---\n",
    "print(\"   Finalizing indices (Linking Transcripts to Genes)...\")\n",
    "\n",
    "# 1. Create Reverse Map (Massive speedup for missing GIDs)\n",
    "tx_reverse_map = {tx: gid for gid, txs in tx_map.items() for tx in txs}\n",
    "\n",
    "final_index = defaultdict(list)\n",
    "# Use list() to force iteration so tqdm works\n",
    "keys = list(cds_index.keys())\n",
    "\n",
    "for key in tqdm(keys, desc=\"Linking\", unit=\" chroms\"):\n",
    "    entries = cds_index[key]\n",
    "    clean_entries = []\n",
    "    \n",
    "    for s, e, tx in entries:\n",
    "        # Fast Lookup 1: Check props\n",
    "        gid = tx_props[tx].get(\"gid\")\n",
    "        \n",
    "        # Fast Lookup 2: Check reverse map\n",
    "        if not gid:\n",
    "            gid = tx_reverse_map.get(tx)\n",
    "            \n",
    "        if gid:\n",
    "            clean_entries.append((s, e, gid))\n",
    "            \n",
    "    # Sort for binary search usage later\n",
    "    final_index[key] = sorted(clean_entries, key=lambda x: x[0])\n",
    "\n",
    "print(f\"‚úÖ Parsed {len(tx_props)} transcripts and built collision indices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9aafbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Processing 424 genes...\n",
      "‚úÖ Complete! Generated 1947 oligos.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 3. EXTRACTION LOOP\n",
    "# ---------------------------------------------------------\n",
    "records, windows, opools, skipped = [], [], [], []\n",
    "\n",
    "print(f\"üöÄ Processing {len(target_genes)} genes...\")\n",
    "\n",
    "for name in target_genes:\n",
    "    # 1. Resolve ID\n",
    "    gid = name_to_id.get(clean_id(name))\n",
    "    if not gid:\n",
    "        skipped.append({\"Gene\": name, \"Reason\": \"Not found in GFF\"})\n",
    "        continue\n",
    "\n",
    "    # 2. Get Isoform Boundaries\n",
    "    isoforms = set()\n",
    "    for tx in tx_map.get(gid, []):\n",
    "        p = tx_props.get(tx)\n",
    "        if p: isoforms.add((p[\"chrom\"], p[\"strand\"], p[\"min\"] if p[\"strand\"] == \"+\" else p[\"max\"]))\n",
    "    \n",
    "    if not isoforms:\n",
    "        skipped.append({\"Gene\": name, \"Reason\": \"No CDS found\"})\n",
    "        continue\n",
    "\n",
    "    # 3. Extract & Clip Upstreams\n",
    "    seen_seqs = set()\n",
    "    for i, (chrom, strand, b1) in enumerate(sorted(isoforms)):\n",
    "        try:\n",
    "            seq_obj = genome[chrom].seq\n",
    "            \n",
    "            # --- CLIPPING LOGIC ---\n",
    "            # Finds nearest neighbor to stop extraction early\n",
    "            limit = 0 if strand == \"+\" else len(seq_obj)\n",
    "            \n",
    "            # Check same strand neighbors\n",
    "            neighbors = final_index.get((chrom, strand), [])\n",
    "            # Check opposite strand neighbors (if configured)\n",
    "            if CONFIG[\"BLOCK_OPPOSITE\"]: neighbors += final_index.get(chrom, [])\n",
    "            \n",
    "            if strand == \"+\":\n",
    "                # Looking upstream (left) on + strand\n",
    "                # Find max END of a neighbor that is < boundary\n",
    "                valid_ends = [e for s, e, g in neighbors if g != gid and e < (b1 - CONFIG[\"CLIP_MARGIN\"])]\n",
    "                floor = max(valid_ends) if valid_ends else 0\n",
    "                \n",
    "                start = max(floor, (b1 - 1) - CONFIG[\"UPSTREAM_LEN\"])\n",
    "                upstream = seq_obj[start : b1 - 1] # Stop before ATG\n",
    "                \n",
    "            else:\n",
    "                # Looking upstream (right) on - strand\n",
    "                # Find min START of a neighbor that is > boundary\n",
    "                valid_starts = [s for s, e, g in neighbors if g != gid and s > (b1 + CONFIG[\"CLIP_MARGIN\"])]\n",
    "                ceil = min(valid_starts) - 1 if valid_starts else len(seq_obj)\n",
    "                \n",
    "                end = min(ceil, b1 + CONFIG[\"UPSTREAM_LEN\"])\n",
    "                upstream = seq_obj[b1 : end].reverse_complement() # Start after ATG\n",
    "            \n",
    "            # --- CHECKS ---\n",
    "            if len(upstream) < CONFIG[\"MIN_LEN\"]: \n",
    "                skipped.append({\"Gene\": f\"{name}_iso{i}\", \"Reason\": \"Too short after clipping\"})\n",
    "                continue\n",
    "                \n",
    "            if str(upstream) in seen_seqs: continue\n",
    "            seen_seqs.add(str(upstream))\n",
    "            \n",
    "            # --- SAVE FULL UPSTREAM ---\n",
    "            tag = f\"{name}\" if len(isoforms) == 1 else f\"{name}_iso{i+1}\"\n",
    "            records.append(SeqRecord(upstream, id=tag, description=\"\"))\n",
    "\n",
    "            # --- WINDOWING & OPOOLS ---\n",
    "            up_len = len(upstream)\n",
    "            step = CONFIG[\"WINDOW_SIZE\"] - CONFIG[\"OVERLAP\"]\n",
    "            # Generate start coordinates (proximal -> distal)\n",
    "            starts = [s for s in range(up_len - CONFIG[\"WINDOW_SIZE\"], -1, -step)]\n",
    "            \n",
    "            for w_idx, s in enumerate(starts, 1):\n",
    "                insert = upstream[s : s + CONFIG[\"WINDOW_SIZE\"]]\n",
    "                if len(insert) != CONFIG[\"WINDOW_SIZE\"]: continue\n",
    "                \n",
    "                # Raw Window\n",
    "                win_tag = f\"{tag}|win{w_idx}\"\n",
    "                windows.append(SeqRecord(insert, id=win_tag, description=\"\"))\n",
    "                \n",
    "                # oPool (Patched + Tails)\n",
    "                patched_seq, mutations = break_bsai(str(insert))\n",
    "                final_seq = CONFIG[\"FWD_TAIL\"] + patched_seq + CONFIG[\"REV_TAIL\"]\n",
    "                \n",
    "                opool_tag = f\"{win_tag}|oPool\" + (f\"|BsaI_mut{mutations}\" if mutations else \"\")\n",
    "                opools.append(SeqRecord(Seq(final_seq), id=opool_tag, description=f\"len={len(final_seq)}\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            skipped.append({\"Gene\": name, \"Reason\": str(e)})\n",
    "\n",
    "print(f\"‚úÖ Complete! Generated {len(opools)} oligos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5fcb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved:\n",
      "1. 01_upstream_20260117_191542.fa\n",
      "2. 02_windows_20260117_191542.fa\n",
      "3. 03_opools_20260117_191542.fa\n",
      "4. skipped_20260117_191542.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. EXPORT\n",
    "# ---------------------------------------------------------\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "f_up   = f\"01_upstream_{ts}.fa\"\n",
    "f_win  = f\"02_windows_{ts}.fa\"\n",
    "f_pool = f\"03_opools_{ts}.fa\"\n",
    "f_xlsx = f\"skipped_{ts}.xlsx\"\n",
    "\n",
    "SeqIO.write(records, f_up, \"fasta\")\n",
    "SeqIO.write(windows, f_win, \"fasta\")\n",
    "SeqIO.write(opools,  f_pool, \"fasta\")\n",
    "\n",
    "# Excel Report\n",
    "df_skip = pd.DataFrame(skipped)\n",
    "if not df_skip.empty:\n",
    "    with pd.ExcelWriter(f_xlsx) as writer:\n",
    "        df_skip[df_skip[\"Reason\"].str.contains(\"Not found\")].to_excel(writer, sheet_name=\"Not Found\", index=False)\n",
    "        df_skip.to_excel(writer, sheet_name=\"All Skipped\", index=False)\n",
    "\n",
    "print(f\"üíæ Saved:\\n1. {f_up}\\n2. {f_win}\\n3. {f_pool}\\n4. {f_xlsx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
